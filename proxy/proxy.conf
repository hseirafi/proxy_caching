#local disk directory for the cache is called /path/to/cache
#levels sets up a two -level directory hierachy under /path/to/chache/
#if level is not included nginx puts all files in the same directory
#keys_zone sets up a shared memeory zone for storing the chche keys: 
#metadata such as usage timer. keys help nginx to quickly determin if a request is a HIT or MiSS 
#without going to disk. 
# max_size sets the upper limit of the size of the cache (to 10 gigabytes in this example). 
#It is optional; not specifying a value allows the cache to grow to use all available disk space.
#When the cache size reaches the limit, a process called the cache manager removes the files that
#were least recently used to bring the cache size back under the limit.
#inactive specifies how long an item can remain in the cache without being accessed. 
#A file that has not been requested for 60 minutes is automatically deleted from the cache by the 
#cache manager process, regardless of whether or not it has expired. The default value is 10 minutes (10m).
#Inactive content differs from expired content. NGINX does not automatically delete content that has expired 
#as defined by a cache control header (Cache-Control:max-age=120 for example). Expired (stale) content is
#deleted only when it has not been accessed for the time specified by inactive. When expired content is
#accessed, NGINX refreshes it from the origin server and resets the inactive timer.
#NGINX first writes files that are destined for the cache to a temporary storage area, and the 
#use_temp_path=off directive instructs NGINX to write them to the same directories where they will be cached.
#We recommend that you set this parameter to off to avoid unnecessary copying of data between file systems.
#use_temp_path was introduced in NGINX version 1.7.10 and
#And finally, the proxy_cache directive activates caching of all content that matches the URL of the parent location block.
#You can also include the proxy_cache directive in a server block; it applies to all location blocks for
#the server that don’t have their own proxy_cache directive. 
# proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g
#                  inactive=60m use_temp_path=off;



server {
    listen 80;
        # set resolver for shorter times to see scaling changes
    resolver 127.0.0.11 valid=50s;
    set $upstream http://app:3000;
    location /{
#proxy_cache_revalidate instructs NGINX to use conditional GET requests when refreshing content from the origin servers. If a client requests an item that is cached but expired as defined by the cache control headers, NGINX includes the If-Modified-Since field in the header of the GET request it sends to the origin server. This saves on bandwidth, because the server sends the full item only if it has been modified since the time recorded in the Last-Modified header attached to the file when NGINX originally cached it.
#proxy_cache_min_uses sets the number of times an item must be requested by clients before NGINX caches it. This is useful if the cache is constantly filling up, as it ensures that only the most frequently accessed items are added to the cache. By default proxy_cache_min_uses is set to 1.
#The updating parameter to the proxy_cache_use_stale directive instructs NGINX to deliver stale content when clients request an item while an update to it is being downloaded from the origin server, instead of forwarding repeated requests to the server. The first user to request a stale file has to wait for it to be updated from the origin server. The stale file is returned for all subsequent requests until the updated file is fully downloaded.
#With proxy_cache_lock enabled, if multiple clients request a file that is not current in the cache (a MISS), only the first of those requests is allowed through to the origin server. The remaining requests wait for that request to be satisfied and then pull the file from the cache. Without proxy_cache_lock enabled, all requests that result in cache misses go straight to the origin server.
        # proxy_cache my_cache;
        # proxy_cache_revalidate on;
        # proxy_cache_min_uses 3;
#A powerful feature of NGINX content caching is that NGINX can be configured to deliver stale content 
#from its cache when it can’t get fresh content from the origin servers. This can happen if all the
#origin servers for a cached resource are down or temporarily busy. Rather than relay the error to the client,
#NGINX delivers the stale version of the file from its cache. This provides an extra level of fault tolerance 
#for the servers that NGINX is proxying, and ensures uptime in the case of server failures or traffic spikes. 
#To enable this functionality, include the proxy_cache_use_stale directive:
        # proxy_cache_use_stale error timeout http_500 http_502 http_503 http_504;
        # nginx passing to simple proxy pass requires a reload
        # to know about other conteriners. 
        # to make nginx dynamic 
       
        proxy_pass $upstream;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
       
    }
}